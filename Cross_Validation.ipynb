{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8x6aBnv63PhFrPJrWqXVh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aadi-kanwar/MLOps/blob/main/Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hold out Cross Validation\n",
        "\n",
        "Hold-out cross-validation is the simplest and most common technique\n",
        "\n",
        "The fact that we test our model only once might be a bottleneck for this method. Due to the reasons mentioned before, the result obtained by the hold-out technique may be considered inaccurate."
      ],
      "metadata": {
        "id": "zPJdPl23vTmO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQLhXeSRvMvw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-Fold Cross Validation\n",
        "\n",
        "k-Fold cross-validation is a technique that minimizes the disadvantages of the hold-out method. k-Fold introduces a new way of splitting the dataset which helps to overcome the “test only once bottleneck”.\n",
        "\n",
        "In general, it is always better to use k-Fold technique instead of hold-out. In a head to head, comparison k-Fold gives a more stable and trustworthy result since training and testing is performed on several different parts of the dataset. We can make the overall score even more robust if we increase the number of folds to test the model on many different sub-datasets.\n",
        "\n",
        "Still, k-Fold method has a disadvantage. Increasing k results in training more models and the training process might be really expensive and time-consuming.\n"
      ],
      "metadata": {
        "id": "JaYFJ_mHv0as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "kf = KFold(n_splits=2)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI2MyVfdvQhM",
        "outputId": "24196126-e9a0-4551-8b5e-5f9d024fd6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [2 3] TEST: [0 1]\n",
            "TRAIN: [0 1] TEST: [2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PRactice Program for K-fold\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "k_folds = KFold(n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdfSPCyZwAPd",
        "outputId": "42e4e309-13c0-4978-e254-07e0c54a3fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1.         1.         0.83333333 0.93333333 0.8       ]\n",
            "Average CV Score:  0.9133333333333333\n",
            "Number of CV Scores used in Average:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leave-one-out сross-validation (LOOCV)\n",
        "\n",
        "Leave-one-out сross-validation (LOOCV) is an extreme case of k-Fold CV. Imagine if k is equal to n where n is the number of samples in the dataset. Such k-Fold case is equivalent to Leave-one-out technique.\n",
        "\n",
        "For LOOCV sklearn also has a built-in method. It can be found in the model_selection library - `sklearn.model_selection.LeaveOneOut.`\n",
        "\n",
        "The greatest advantage of Leave-one-out cross-validation is that it doesn’t waste much data. We use only one sample from the whole dataset as a test set, whereas the rest is the training set. But when compared with k-Fold CV, LOOCV requires building n models instead of k models, when we know that n which stands for the number of samples in the dataset is much higher than k. It means LOOCV is more computationally expensive than k-Fold, it may take plenty of time to cross-validate the model using LOOCV.\n",
        "\n",
        "Thus, the Data Science community has a general rule based on empirical evidence and different researches, which suggests that 5- or 10-fold cross-validation should be preferred over LOOCV.\n"
      ],
      "metadata": {
        "id": "mUA3Z9b4xxtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "X = np.array([[1, 2], [3, 4]])\n",
        "y = np.array([1, 2])\n",
        "loo = LeaveOneOut()\n",
        "for train_index, test_index in loo.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8EO2aqkwU4W",
        "outputId": "0c779b41-5ca8-4226-db4c-538d0df9635d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1] TEST: [0]\n",
            "TRAIN: [0] TEST: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice program for LOOCV\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = loo)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnELJ4viyNbU",
        "outputId": "9a400f5d-cc11-4f40-ea74-93eb54c48fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "Average CV Score:  0.94\n",
            "Number of CV Scores used in Average:  150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leave-p-out cross-validation\n",
        "\n",
        "Leave-p-out cross-validation (LpOC) is similar to Leave-one-out CV as it creates all the possible training and test sets by using p samples as the test set. All mentioned about LOOCV is true and for LpOC.\n",
        "\n",
        "Still, it is worth mentioning that unlike LOOCV and k-Fold test sets will overlap for LpOC if p is higher than 1.\n",
        "\n",
        "You can perform Leave-p-out CV using sklearn - `sklearn.model_selection.LeavePOut`\n",
        "\n",
        "LpOC has all the disadvantages of the LOOCV, but, nevertheless, it's as robust as LOOCV."
      ],
      "metadata": {
        "id": "Ed30LDEdf2xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeavePOut\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
        "y = np.array([1, 2, 3, 4])\n",
        "lpo = LeavePOut(2)\n",
        "for train_index, test_index in lpo.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frunTIeBgDNJ",
        "outputId": "7410d705-edf4-45a7-a841-a9d0d09a7dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [2 3] TEST: [0 1]\n",
            "TRAIN: [1 3] TEST: [0 2]\n",
            "TRAIN: [1 2] TEST: [0 3]\n",
            "TRAIN: [0 3] TEST: [1 2]\n",
            "TRAIN: [0 2] TEST: [1 3]\n",
            "TRAIN: [0 1] TEST: [2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PRactice Program for LpOC\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeavePOut, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "lpo = LeavePOut(p=2)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = lpo)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AarWBOxugFt5",
        "outputId": "687c8095-68f4-49a4-9dc6-31a273aa606b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1. 1. 1. ... 1. 1. 1.]\n",
            "Average CV Score:  0.9382997762863534\n",
            "Number of CV Scores used in Average:  11175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratified k-Fold cross-validation\n",
        "Stratified k-Fold is a variation of the standard k-Fold CV technique which is designed to be effective in such cases of target imbalance.\n",
        "\n",
        "It works as follows. Stratified k-Fold splits the dataset on k folds such that each fold contains approximately the same percentage of samples of each target class as the complete set. In the case of regression, Stratified k-Fold makes sure that the mean target value is approximately equal in all the folds.\n",
        "\n",
        "Stratified k-Fold also has a built-in method in sklearn - `sklearn.model_selection.StratifiedKFold`\n",
        "\n"
      ],
      "metadata": {
        "id": "E3CLkpTUgcaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "skf = StratifiedKFold(n_splits=2)\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK72JnKbgUSb",
        "outputId": "29486053-ce22-43d6-850b-2dafee8400de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1 3] TEST: [0 2]\n",
            "TRAIN: [0 2] TEST: [1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice Program for Stratified k-Fold Cross Validations\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "sk_folds = StratifiedKFold(n_splits = 2)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = sk_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25QXh5vMgxgk",
        "outputId": "224dc119-cbaa-4024-d1c8-c931f3a7d7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [0.96 0.96]\n",
            "Average CV Score:  0.96\n",
            "Number of CV Scores used in Average:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeated k-Fold Cross Validation\n",
        "Repeated k-Fold cross-validation or Repeated random sub-sampling CV is probably the most robust of all CV techniques in this paper. It is a variation of k-Fold but in the case of Repeated k-Folds k is not the number of folds. It is the number of times we will train the model.\n",
        "\n",
        "Sklearn will help you to implement a Repeated k-Fold CV. Just use - `sklearn.model_selection.RepeatedKFold`\n",
        "\n",
        "In sklearn implementation of this technique you must set the number of folds that you want to have (n_splits) and the number of times the split will be performed (n_repeats). It guarantees that you will have different folds on each iteration."
      ],
      "metadata": {
        "id": "AdpDzzUGjiYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=42)\n",
        "for train_index, test_index in rkf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLRL9bB_hczw",
        "outputId": "008ad7e7-dae5-4e41-9dce-485ad1b8ca0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [0 2] TEST: [1 3]\n",
            "TRAIN: [1 3] TEST: [0 2]\n",
            "TRAIN: [0 2] TEST: [1 3]\n",
            "TRAIN: [1 3] TEST: [0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nested k-Fold\n",
        "Nested k-fold CV is used to train a model in which hyperparameters also need to be optimized. It estimates the generalization error of the underlying model and its (hyper)parameter search.\n"
      ],
      "metadata": {
        "id": "r4nMDIxvkCR1"
      }
    }
  ]
}